{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import onnx\n",
    "import onnxruntime\n",
    "from collections import defaultdict\n",
    "# Navigate to the parent directory\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "from src.config import MODEL_PATH, INPUT_SHAPE,OUTPUT_NAME,INPUT_NAME,session,CLASS_NAMES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to your model\n",
    "MODEL_PATH = '/Users/alaindestinkarasira/Documents/Malaria_Diagnosis_/src/models/weights/best.onnx'\n",
    "SEVERITY_THRESHOLD=10\n",
    "# Function to load the model and create a session\n",
    "def load_model(model_path):\n",
    "    # Load the ONNX model\n",
    "    model = onnx.load(model_path)\n",
    "    # Create an ONNX Runtime session\n",
    "    session = onnxruntime.InferenceSession(model_path)\n",
    "    return model, session\n",
    "\n",
    "# Load the model and session\n",
    "model, session = load_model(MODEL_PATH)\n",
    "\n",
    "# Get model input and output details\n",
    "INPUT_NAME = session.get_inputs()[0].name\n",
    "INPUT_SHAPE = session.get_inputs()[0].shape\n",
    "OUTPUT_NAME = session.get_outputs()[0].name\n",
    "\n",
    "# Optionally, load class names from the model metadata\n",
    "CLASS_NAMES = {}\n",
    "for prop in model.metadata_props:\n",
    "    if prop.key == \"names\" or prop.key == \"classes\":\n",
    "        CLASS_NAMES=eval(prop.value)  # Be cautious with eval\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images\n",
      "[1, 3, 640, 640]\n",
      "output0\n",
      "{0: 'PF', 1: 'PM', 2: 'PO', 3: 'PV'}\n"
     ]
    }
   ],
   "source": [
    "print (INPUT_NAME)\n",
    "print (INPUT_SHAPE)\n",
    "print (OUTPUT_NAME)\n",
    "print(CLASS_NAMES)\n",
    "dets=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the image\n",
    "def preprocess_image(image_path, input_shape):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (input_shape[2], input_shape[3]))\n",
    "    image = image.transpose(2, 0, 1)\n",
    "    image = np.expand_dims(image, 0)\n",
    "    image = image.astype(np.float32) / 255.0\n",
    "    return image\n",
    "\n",
    "# def run_inference(session, image):\n",
    "#     input_name = session.get_inputs()[0].name\n",
    "#     output_names = [output.name for output in session.get_outputs()]\n",
    "#     outputs = session.run(output_names, {input_name: image})\n",
    "#     return outputs\n",
    "\n",
    "def run_inference(image,output_name,input_name):\n",
    "    results = session.run([output_name], {input_name: image})\n",
    "    # print(results[0].shape)  # Print raw model output for debugging\n",
    "\n",
    "    return results[0]\n",
    "\n",
    "\n",
    "# Process detections\n",
    "# def process_detections(detections, confidence_threshold=0.2):\n",
    "#     results = []\n",
    "#     for detection in detections[0]:\n",
    "#         score = float(detection[4])\n",
    "#         if score > confidence_threshold:\n",
    "#             class_id = int(detection[5])\n",
    "#             class_name = CLASS_NAMES.get(class_id, str(class_id))\n",
    "#             bbox = detection[0:4].tolist()\n",
    "#             results.append({\n",
    "#                 'class': class_id,\n",
    "#                 'class name': class_name,\n",
    "#                 'confidence': score,\n",
    "#                 'bbox': bbox\n",
    "#             })\n",
    "#     return results\n",
    "\n",
    "\n",
    "def process_detections(detections, confidence_threshold=0.4):\n",
    "    results = []\n",
    "    for detection in detections[0]:  # Iterate over all detections\n",
    "        objectness = float(detection[4])\n",
    "        class_scores = detection[5:]  # The rest are class scores\n",
    "        class_id = int(np.argmax(class_scores))\n",
    "        confidence = class_scores[class_id]\n",
    "        \n",
    "        if objectness > confidence_threshold and confidence > confidence_threshold:\n",
    "            class_name = CLASS_NAMES.get(class_id, str(class_id))\n",
    "            bbox = detection[0:4].tolist()\n",
    "            results.append({\n",
    "                'class': class_id,\n",
    "                'class_name': class_name,\n",
    "                'confidence': confidence,\n",
    "                'bbox': bbox\n",
    "            })\n",
    "    return results\n",
    "def process_patient_images(patient_id, image_folder, temp_storage):\n",
    "    # Ensure the image folder path is a Path object\n",
    "    image_folder = Path(image_folder)\n",
    "    \n",
    "    # Get all image files in the folder\n",
    "    image_files = [f for f in image_folder.iterdir() if f.is_file() and f.suffix.lower() in ('.jpg', '.jpeg', '.png', '.bmp')]\n",
    "    \n",
    "    for image_file in image_files:\n",
    "        # Generate an image ID based on the filename\n",
    "        image_id = f\"{patient_id}_{image_file.stem}\"\n",
    "        \n",
    "        # Preprocess the image\n",
    "        image = preprocess_image(str(image_file), INPUT_SHAPE)\n",
    "        \n",
    "        # Run inference\n",
    "        detections = run_inference(image,OUTPUT_NAME,INPUT_NAME)\n",
    "        # print(detections)\n",
    "        \n",
    "        # Process detections\n",
    "        results = process_detections(detections, confidence_threshold=0.5)\n",
    "        \n",
    "        # Save the results to temporary storage\n",
    "        temp_storage.save_detection(patient_id, image_id, results)\n",
    "\n",
    "# def process_patient_images(patient_id, image_folder, temp_storage):\n",
    "#     # Ensure the image folder path is a Path object\n",
    "#     image_folder = Path(image_folder)\n",
    "    \n",
    "#     # Get all image files in the folder\n",
    "#     image_files = [f for f in image_folder.iterdir() if f.is_file() and f.suffix.lower() in ('.jpg', '.jpeg', '.png', '.bmp')]\n",
    "    \n",
    "#     for image_file in image_files:\n",
    "#         # Generate an image ID based on the filename\n",
    "#         image_id = f\"{patient_id}_{image_file.stem}\"\n",
    "        \n",
    "#         print(f\"\\nProcessing image: {image_file.name}\")\n",
    "        \n",
    "#         # Preprocess the image\n",
    "#         image = preprocess_image(str(image_file), INPUT_SHAPE)\n",
    "        \n",
    "#         # Run inference\n",
    "#         detections = run_inference(image, OUTPUT_NAME,INPUT_NAME )\n",
    "        \n",
    "#         # Print raw detections\n",
    "#         print(\"Raw detections:\")\n",
    "#         for i, detection in enumerate(detections):\n",
    "#             print(f\"Detection {i}:\")\n",
    "#             print(detection)\n",
    "        \n",
    "#         # Process detections\n",
    "#         results = process_detections(detections, CLASS_NAMES, confidence_threshold=0.5)\n",
    "        \n",
    "#         # Print processed results\n",
    "#         print(\"\\nProcessed results:\")\n",
    "#         for result in results:\n",
    "#             print(f\"Class: {result['class_name']}\")\n",
    "#             print(f\"Confidence: {result['confidence']:.2f}\")\n",
    "#             print(f\"Bounding Box: {result['bbox']}\")\n",
    "#             print()\n",
    "        \n",
    "#         # Save the results to temporary storage\n",
    "#         temp_storage.save_detection(patient_id, image_id, results)\n",
    "        \n",
    "#         print(f\"Results saved for image: {image_file.name}\")\n",
    "#         print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TempStorage:\n",
    "    def __init__(self):\n",
    "        self.patient_detections = defaultdict(list)\n",
    "\n",
    "    def save_detection(self, patient_id, image_id, detection_results):\n",
    "        self.patient_detections[patient_id].append({\n",
    "            \"image_id\": image_id,\n",
    "            \"results\": detection_results\n",
    "        })\n",
    "\n",
    "    def get_patient_detections(self, patient_id):\n",
    "        return self.patient_detections.get(patient_id, [])\n",
    "\n",
    "def aggregate_and_assess_severity(image_results, severity_threshold):\n",
    "    aggregated_results = {}\n",
    "\n",
    "    # Aggregate data across all images\n",
    "    for result in image_results:\n",
    "        for parasite in result[\"results\"]:\n",
    "            parasite_type = parasite[\"class_name\"]\n",
    "            confidence = parasite[\"confidence\"]\n",
    "\n",
    "            if parasite_type not in aggregated_results:\n",
    "                aggregated_results[parasite_type] = {\n",
    "                    \"count\": 0,\n",
    "                    \"total_confidence\": 0.0,\n",
    "                    \"instances\": 0\n",
    "                }\n",
    "\n",
    "            aggregated_results[parasite_type][\"count\"] += 1\n",
    "            aggregated_results[parasite_type][\"total_confidence\"] += confidence\n",
    "            aggregated_results[parasite_type][\"instances\"] += 1\n",
    "\n",
    "    # Calculate average confidence\n",
    "    for parasite_type, data in aggregated_results.items():\n",
    "        data[\"average_confidence\"] = (\n",
    "            data[\"total_confidence\"] / data[\"instances\"]\n",
    "            if data[\"instances\"] > 0 else 0\n",
    "        )\n",
    "\n",
    "    # Determine severity\n",
    "    total_parasite_count = sum(data[\"count\"] for data in aggregated_results.values())\n",
    "    severity = \"Mild\" if total_parasite_count < severity_threshold else \"Severe\"\n",
    "\n",
    "    return aggregated_results, severity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing images for patient ID: pat_001 in folder: /Users/alaindestinkarasira/Documents/Malaria_Diagnosis_/data/External\n",
      "(1, 25200, 9)\n",
      "(1, 25200, 9)\n",
      "(1, 25200, 9)\n",
      "(1, 25200, 9)\n",
      "(1, 25200, 9)\n",
      "(1, 25200, 9)\n",
      "(1, 25200, 9)\n",
      "(1, 25200, 9)\n",
      "Parasite Type: PV\n",
      "  Count: 27\n",
      "  Average Confidence: 0.95\n",
      "  Severity: 25.62\n",
      "  Severity Level: high\n",
      "\n",
      "Parasite Type: PO\n",
      "  Count: 20\n",
      "  Average Confidence: 0.79\n",
      "  Severity: 15.70\n",
      "  Severity Level: high\n",
      "\n",
      "Aggregated Instances: PV\n",
      "Severity: PO\n"
     ]
    }
   ],
   "source": [
    "# Hardcoded patient ID and image folder path\n",
    "patient_id = \"pat_001\"\n",
    "image_folder = \"/Users/alaindestinkarasira/Documents/Malaria_Diagnosis_/data/External\"  # Ensure the case matches\n",
    "\n",
    "# Log the received request and paths\n",
    "print(f\"Processing images for patient ID: {patient_id} in folder: {image_folder}\")\n",
    "\n",
    "# Create a temporary storage instance\n",
    "temp_storage = TempStorage()\n",
    "\n",
    "# Process the images for the given patient\n",
    "process_patient_images(patient_id, image_folder, temp_storage)\n",
    "\n",
    "# Aggregate results and assess severity\n",
    "aggregated_results, severity = aggregate_and_assess_severity(\n",
    "    temp_storage.get_patient_detections(patient_id), 2\n",
    ")\n",
    "\n",
    "# Log the results\n",
    "# print(f\"Aggregated Instances: {aggregated_results['instances']}\")\n",
    "print(f\"Aggregated Instances: {aggregated_results}\")\n",
    "\n",
    "print(f\"Severity: {severity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(dets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_and_assess_severity(image_results, severity_threshold):\n",
    "    aggregated_results = {}\n",
    "\n",
    "    # Aggregate data across all images\n",
    "    for result in image_results:\n",
    "        seen_parasites = set()  # To avoid double counting in the same image\n",
    "        for parasite in result[\"results\"]:\n",
    "            parasite_type = parasite[\"class_name\"]\n",
    "            confidence = parasite[\"confidence\"]\n",
    "\n",
    "            # Unique key to identify each detected instance by class and bounding box\n",
    "            unique_key = (parasite_type, tuple(parasite[\"bbox\"]))\n",
    "\n",
    "            if unique_key not in seen_parasites:\n",
    "                seen_parasites.add(unique_key)\n",
    "\n",
    "                if parasite_type not in aggregated_results:\n",
    "                    aggregated_results[parasite_type] = {\n",
    "                        \"count\": 0,\n",
    "                        \"total_confidence\": 0.0,\n",
    "                        \"instances\": 0\n",
    "                    }\n",
    "\n",
    "                aggregated_results[parasite_type][\"count\"] += 1\n",
    "                aggregated_results[parasite_type][\"total_confidence\"] += confidence\n",
    "                aggregated_results[parasite_type][\"instances\"] += 1\n",
    "\n",
    "    # Calculate average confidence and severity, and print results\n",
    "    severity_results = {}\n",
    "    for parasite_type, data in aggregated_results.items():\n",
    "        data[\"average_confidence\"] = (\n",
    "            data[\"total_confidence\"] / data[\"instances\"]\n",
    "            if data[\"instances\"] > 0 else 0\n",
    "        )\n",
    "        # Example severity computation: (count * average_confidence)\n",
    "        severity = data[\"count\"] * data[\"average_confidence\"]\n",
    "\n",
    "        # Assess severity based on the threshold\n",
    "        severity_level = \"low\"\n",
    "        if severity > severity_threshold:\n",
    "            severity_level = \"high\"\n",
    "        \n",
    "        # Store the results\n",
    "        severity_results[parasite_type] = {\n",
    "            \"severity\": severity,\n",
    "            \"severity_level\": severity_level,\n",
    "            \"count\": data[\"count\"],\n",
    "            \"average_confidence\": data[\"average_confidence\"]\n",
    "        }\n",
    "        \n",
    "        # Print the aggregated results and severity level\n",
    "        print(f\"Parasite Type: {parasite_type}\")\n",
    "        print(f\"  Count: {data['count']}\")\n",
    "        print(f\"  Average Confidence: {data['average_confidence']:.2f}\")\n",
    "        print(f\"  Severity: {severity:.2f}\")\n",
    "        print(f\"  Severity Level: {severity_level}\")\n",
    "        print()\n",
    "\n",
    "    return severity_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parasite Type: PV\n",
      "  Count: 27\n",
      "  Average Confidence: 0.95\n",
      "  Severity: 25.62\n",
      "  Severity Level: high\n",
      "\n",
      "Parasite Type: PO\n",
      "  Count: 20\n",
      "  Average Confidence: 0.79\n",
      "  Severity: 15.70\n",
      "  Severity Level: high\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PV': {'severity': 25.621412217617035,\n",
       "  'severity_level': 'high',\n",
       "  'count': 27,\n",
       "  'average_confidence': 0.9489411932450754},\n",
       " 'PO': {'severity': 15.702557981014252,\n",
       "  'severity_level': 'high',\n",
       "  'count': 20,\n",
       "  'average_confidence': 0.7851278990507126}}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_and_assess_severity(temp_storage.get_patient_detections(patient_id), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NOC_Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
